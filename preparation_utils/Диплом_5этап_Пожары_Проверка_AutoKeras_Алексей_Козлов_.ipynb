{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuzGFBfS-Jeg",
        "outputId": "34128775-09c2-463d-d0ed-e6a8bcf46f14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autokeras\n",
            "  Downloading autokeras-2.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autokeras) (24.1)\n",
            "Collecting keras-tuner>=1.4.0 (from autokeras)\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting keras-nlp>=0.8.0 (from autokeras)\n",
            "  Downloading keras_nlp-0.17.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from autokeras) (3.4.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from autokeras) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.4.1)\n",
            "Collecting keras-hub==0.17.0 (from keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading keras_hub-0.17.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (2024.9.11)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (0.3.3)\n",
            "Collecting tensorflow-text (from keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner>=1.4.0->autokeras) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner>=1.4.0->autokeras)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.0.0->autokeras) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->autokeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->autokeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->autokeras) (0.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (4.66.6)\n",
            "Collecting tensorflow<2.19,>=2.18.0 (from tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (1.64.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.0.0 (from autokeras)\n",
            "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (0.44.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras-nlp>=0.8.0->autokeras) (3.0.2)\n",
            "Downloading autokeras-2.0.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.7/122.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_nlp-0.17.0-py3-none-any.whl (2.0 kB)\n",
            "Downloading keras_hub-0.17.0-py3-none-any.whl (644 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.1/644.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Downloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kt-legacy, tensorboard, keras, tensorflow, keras-tuner, tensorflow-text, keras-hub, keras-nlp, autokeras\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed autokeras-2.0.0 keras-3.6.0 keras-hub-0.17.0 keras-nlp-0.17.0 keras-tuner-1.4.7 kt-legacy-1.0.5 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-text-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "import gdown\n",
        "import time\n",
        "import datetime\n",
        "from tensorflow.keras.models import load_model #загрузка сохраненной модели"
      ],
      "metadata": {
        "id": "izwhIBXP-NxQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#~ фиксирую время начала выполнения процесса\n",
        "time1 = time.time()"
      ],
      "metadata": {
        "id": "7cgWSEnl-xBR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#~ скачиваем данные\n",
        "#~ 20241108_1102_trial4_epocs10_50_greedy_acc96_2\n",
        "# gdown.download('https://drive.google.com/uc?export=download&confirm=no_antivirus&id=1fSaHbJhd_hZUxL_ul6m93VFbgq5O6Xr7', None, quiet=True)\n",
        "#~ 20241108_1659_trial4_epocs10_40_bayesian_acc_96_2\n",
        "gdown.download('https://drive.google.com/uc?export=download&confirm=no_antivirus&id=14Hd7IaCJeJgWf5SMHlKEY4vSdnGDpQpl', None, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XK4V_EYQgbxx",
        "outputId": "60c41fef-1b27-4986-9547-1c9677b39892"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset_fire5_check_bayesian.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -qo dataset_fire5_check.zip -d /content/\n",
        "!unzip -qo dataset_fire5_check_bayesian.zip -d /content/"
      ],
      "metadata": {
        "id": "KGaepOt4muw3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_fname1 = '/content/dataset_fire5_check/model_greedy/model20241108k.keras'\n",
        "model_fname1 = '/content/dataset_fire5_check_bayesian/model_bayesian/model20241108k.keras'\n",
        "print(f'[INFO] model_fname1: `{model_fname1}`')\n",
        "model = load_model(model_fname1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBEl_2OdnTcS",
        "outputId": "1db9d1a3-4441-472d-83bf-202af5245088"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] model_fname1: `/content/dataset_fire5_check_bayesian/model_bayesian/model20241108k.keras`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 4 variables whereas the saved optimizer has 6 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#~ проверяем архитектуру модели\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "lbKz26-Hnkeb",
        "outputId": "547a75b7-77cb-4ed1-ca9a-e5ae6a1e022f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ cast_to_float32 (\u001b[38;5;33mCastToFloat32\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ random_flip (\u001b[38;5;33mRandomFlip\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │         \u001b[38;5;34m100,353\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ classification_head_1 (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ cast_to_float32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CastToFloat32</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ random_flip (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,353</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ classification_head_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,062,188\u001b[0m (80.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,062,188</span> (80.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,353\u001b[0m (392.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,353</span> (392.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m100,355\u001b[0m (392.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,355</span> (392.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#~ keras image width,height ширина-высота изображения, на котором произведено обучение keras\n",
        "kerasimg_wh1 = 224\n",
        "print(f'[INFO] kerasimg_wh1: {kerasimg_wh1}')\n",
        "#~ список категорий классов\n",
        "classes_lst1 = ['fire', 'non-fire']\n",
        "print(f'[INFO] classes_lst1: len: {len(classes_lst1)}, `{classes_lst1}`')\n",
        "#~ rep - report\n",
        "rep_img_width2 = 960\n",
        "rep_img_height2 = 540\n",
        "print(f'[INFO] rep_img_width2: {rep_img_width2}, rep_img_height2: {rep_img_height2}')\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "#~ указываем размер изображения, на котором была обучена нейронка\n",
        "#~ первое значение — это ширина,\n",
        "#~ второе значение — это высота.\n",
        "target_size=(kerasimg_wh1, kerasimg_wh1)\n",
        "#~ размер кадра для отчетного документа rep - report\n",
        "reptarget_size=(rep_img_width2, rep_img_height2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31Cpl8HzoTfX",
        "outputId": "88f66f12-cbfa-4e53-dca7-f94f39e9a547"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] kerasimg_wh1: 224\n",
            "[INFO] classes_lst1: len: 2, `['fire', 'non-fire']`\n",
            "[INFO] rep_img_width2: 960, rep_img_height2: 540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#~ функция для получения списка имен image-файлов\n",
        "def get_image_list(directory_path: str) -> list[str]:\n",
        "  img_lst = []\n",
        "  #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "  if not os.path.exists(directory_path):\n",
        "    return img_lst\n",
        "  #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "  for fname in os.listdir(directory_path):\n",
        "    if os.path.isfile(os.path.join(directory_path, fname)):\n",
        "      if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
        "        img_lst.append(fname)\n",
        "  #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "  return img_lst"
      ],
      "metadata": {
        "id": "HSe248C3n4_8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#~ `IMG_0035.JPG` -> base_fname: `IMG_0035`, suffix_fname: `.JPG`\n",
        "def get_fname_base_suffix(file_name: str) -> tuple:\n",
        "  #~ разделяем имя файла и расширение\n",
        "  #~ находим индекс последней точки в строке\n",
        "  last_dot_index = file_name.rfind('.')\n",
        "  #~ возвращаем подстроку начиная с начала строки до последней точки включительно\n",
        "  base_fname = file_name[:last_dot_index]\n",
        "  #~ расширение\n",
        "  suffix_fname = file_name[last_dot_index:]\n",
        "  #~ возвращаем имя и расширение\n",
        "  return base_fname,suffix_fname"
      ],
      "metadata": {
        "id": "7ffM7byZuTMA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_check(src_dir1: str, is_test_img2: bool, test_class_inx2: int, dst_dir2: str):\n",
        "  print(f'[INFO] src_dir1: `{src_dir1}`')\n",
        "  print(f'[INFO] is_test_img2: {is_test_img2}')\n",
        "  print(f'[INFO] test_class_inx2: {test_class_inx2}')\n",
        "  print(f'[INFO] dst_dir2: `{dst_dir2}`')\n",
        "  #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "  #~ создаю директорию для результатов\n",
        "  if not os.path.exists(dst_dir2):\n",
        "    os.makedirs(dst_dir2)\n",
        "  #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "  img_lst1 = get_image_list(src_dir1)\n",
        "  img_lst_len1 = len(img_lst1)\n",
        "  if img_lst_len1 < 1:\n",
        "    print('[WARNING]  img_lst1 is empty')\n",
        "    return\n",
        "  #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "  #~ побежали по изображениям в списке\n",
        "  for i in range(img_lst_len1):\n",
        "    # print('~'*70)\n",
        "    print(f'[INFO]  {i}->{img_lst_len1-1}: `{img_lst1[i]}`')\n",
        "    img_fname1 = os.path.join(src_dir1, img_lst1[i])\n",
        "    base_fname1,suffix_fname1 = get_fname_base_suffix(img_lst1[i])\n",
        "    # print(f'[INFO]  img_fname1: `{img_fname1}`')\n",
        "    # print(f'[INFO]  base_fname1: `{base_fname1}`, suffix_fname1: `{suffix_fname1}`')\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    #~ проверяем изображение на корректность\n",
        "    frame = cv2.imread(img_fname1)\n",
        "    img_width1 = 0\n",
        "    img_height1 = 0\n",
        "    try:\n",
        "      img_width1 = frame.shape[1]\n",
        "      img_height1 = frame.shape[0]\n",
        "    except:\n",
        "      print(f'[WARNING] corrupted image: `{img_fname1}`')\n",
        "      continue\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    #~ масштабирование/сжатие изображения до размеров 224x224\n",
        "    #~ и предсказание модели\n",
        "    #~ в любом случае сжимаем, так как видео-камер с разрешение 224x224 не бывает\n",
        "    #~ а изображение скорее всего с видеокамеры\n",
        "    frame224 = cv2.resize(frame, target_size, interpolation=cv2.INTER_AREA)\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    #~ для сохранения отчетных кадров -> поджимаем по размерам\n",
        "    if not is_test_img2:\n",
        "      if img_width1 != rep_img_width2 or img_height1 != rep_img_height2:\n",
        "        frame = cv2.resize(frame, reptarget_size, interpolation=cv2.INTER_AREA)\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    #~ для предсказания нормализуем значения пикселей - делим на 255, приводим к диапазону [0..1]\n",
        "    frame224 = frame224/255.0\n",
        "    #~ добавление одной оси в начале, чтобы нейронка могла распознать пример\n",
        "    Xexd = np.expand_dims(frame224, axis=0)\n",
        "    #~ распознавание примера изображения - определение его класса\n",
        "    prediction = model.predict(Xexd, verbose=0)\n",
        "    pred_inx = 0\n",
        "    feature_color = (0, 0, 255)\n",
        "    rect_width = 118\n",
        "    rect_height = 25\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    if is_test_img2:\n",
        "      rect_height = 48\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    class_lbl = f'original: {classes_lst1[test_class_inx2]}'\n",
        "    class_color = (0, 0, 255)\n",
        "    if test_class_inx2 == 1:\n",
        "      rect_width = 168\n",
        "      class_color = (255, 0, 0)\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    if prediction[0][0] > 0.5:\n",
        "      pred_inx = 1\n",
        "      feature_color = (255, 0, 0)\n",
        "      rect_width = 168\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    if not is_test_img2:\n",
        "      rect_width = 115\n",
        "      if prediction[0][0] > 0.5:\n",
        "        rect_width = 165\n",
        "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "    #~ сохраняем продетектированное изображение\n",
        "    img_fname2 = os.path.join(dst_dir2, base_fname1+'.png')\n",
        "    pred_lbl = f'predict: {classes_lst1[pred_inx]}'\n",
        "    cv2.rectangle(frame, (0,0), (rect_width,rect_height), (255,255,255), -1)\n",
        "    if is_test_img2:\n",
        "      cv2.putText(frame, class_lbl, (2,17), cv2.FONT_HERSHEY_SIMPLEX, 0.6, class_color, 1, cv2.LINE_AA)\n",
        "      cv2.putText(frame, pred_lbl, (2,40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, feature_color, 1, cv2.LINE_AA)\n",
        "    else:\n",
        "      cv2.putText(frame, pred_lbl, (2,17), cv2.FONT_HERSHEY_SIMPLEX, 0.6, feature_color, 1, cv2.LINE_AA)\n",
        "    cv2.imwrite(img_fname2, frame)"
      ],
      "metadata": {
        "id": "uGrqPtsdoI8B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#~ провека на тестовых изображениях fire\n",
        "# src_dir1 = '/content/dataset_fire5_check/fire'\n",
        "src_dir1 = '/content/dataset_fire5_check_bayesian/fire'\n",
        "is_test_img2 = True\n",
        "test_class_inx2 = 0\n",
        "dst_dir2 = '/content/dataset_fire5_check_result/fire'\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "image_check(src_dir1, is_test_img2, test_class_inx2, dst_dir2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sUuFwLjpuM3",
        "outputId": "5abeef26-d8b2-4287-e117-e31760ca95d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] src_dir1: `/content/dataset_fire5_check_bayesian/fire`\n",
            "[INFO] is_test_img2: True\n",
            "[INFO] test_class_inx2: 0\n",
            "[INFO] dst_dir2: `/content/dataset_fire5_check_result/fire`\n",
            "[INFO]  0->2: `f_01172-1f22d90b-7104-11ef-bb98-bcee7b784ecb.jpg`\n",
            "[INFO]  1->2: `f_01179-1f24d4d9-7104-11ef-a48f-bcee7b784ecb.jpg`\n",
            "[INFO]  2->2: `f_01176-1f23ea7e-7104-11ef-8f90-bcee7b784ecb.jpg`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#~ провека на тестовых изображениях non-fire\n",
        "# src_dir1 = '/content/dataset_fire5_check/non-fire'\n",
        "src_dir1 = '/content/dataset_fire5_check_bayesian/non-fire'\n",
        "is_test_img2 = True\n",
        "test_class_inx2 = 1\n",
        "dst_dir2 = '/content/dataset_fire5_check_result/non-fire'\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "image_check(src_dir1, is_test_img2, test_class_inx2, dst_dir2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w59D7b8jw8iD",
        "outputId": "23386e95-6279-444a-bf19-13c9665bbbc6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] src_dir1: `/content/dataset_fire5_check_bayesian/non-fire`\n",
            "[INFO] is_test_img2: True\n",
            "[INFO] test_class_inx2: 1\n",
            "[INFO] dst_dir2: `/content/dataset_fire5_check_result/non-fire`\n",
            "[INFO]  0->2: `nf_01171-fcf6020f-7110-11ef-817c-bcee7b784ecb.jpg`\n",
            "[INFO]  1->2: `nf_01173-fcf6c5bd-7110-11ef-8698-bcee7b784ecb.jpg`\n",
            "[INFO]  2->2: `nf_01170-fcf5b3e5-7110-11ef-81b3-bcee7b784ecb.jpg`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#~ провека на тестовых изображениях video_frame, которые были скачаны из интернета\n",
        "# src_dir1 = '/content/dataset_fire5_check/video_frame'\n",
        "src_dir1 = '/content/dataset_fire5_check_bayesian/video_frame'\n",
        "is_test_img2 = False\n",
        "dst_dir2 = '/content/dataset_fire5_check_result/video_frame'\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "image_check(src_dir1, is_test_img2, test_class_inx2, dst_dir2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvb_A-UbxlYQ",
        "outputId": "cad708d6-989a-416e-9c9c-36c022b5436c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] src_dir1: `/content/dataset_fire5_check_bayesian/video_frame`\n",
            "[INFO] is_test_img2: False\n",
            "[INFO] test_class_inx2: 1\n",
            "[INFO] dst_dir2: `/content/dataset_fire5_check_result/video_frame`\n",
            "[INFO]  0->5: `f00121-44a249ec-7b41-11ef-9e7b-bcee7b784ecb.png`\n",
            "[INFO]  1->5: `f00025-4f099448-7b40-11ef-a39f-bcee7b784ecb.png`\n",
            "[INFO]  2->5: `f00038-2a9a1361-7b40-11ef-84a2-bcee7b784ecb.png`\n",
            "[INFO]  3->5: `f00046-3f9da6bf-7b41-11ef-b365-bcee7b784ecb.png`\n",
            "[INFO]  4->5: `f00083-422478a9-7b41-11ef-bd18-bcee7b784ecb.png`\n",
            "[INFO]  5->5: `f00012-d95de3c6-7b40-11ef-b51c-bcee7b784ecb.png`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#~ архивируем результаты, чтобы их можно было скачать\n",
        "archive_time = datetime.datetime.now()\n",
        "archive2 = f'/content/result_fire5_check_{archive_time.strftime(\"%Y%m%d_%H%M%S\")}.zip'\n",
        "dst_dir2 = '/content/dataset_fire5_check_result'\n",
        "print(f'[INFO] archive2: `{archive2}`')\n",
        "print(f'[INFO] dst_dir2: `{dst_dir2}`')\n",
        "!zip -r {archive2} {dst_dir2}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXEwbS-flao3",
        "outputId": "14b3b7a4-3a26-4c92-e89a-76c222bfed7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] archive2: `/content/result_fire5_check_20241108_153023.zip`\n",
            "[INFO] dst_dir2: `/content/dataset_fire5_check_result`\n",
            "  adding: content/dataset_fire5_check_result/ (stored 0%)\n",
            "  adding: content/dataset_fire5_check_result/video_frame/ (stored 0%)\n",
            "  adding: content/dataset_fire5_check_result/video_frame/f00121-44a249ec-7b41-11ef-9e7b-bcee7b784ecb.png (deflated 8%)\n",
            "  adding: content/dataset_fire5_check_result/video_frame/f00025-4f099448-7b40-11ef-a39f-bcee7b784ecb.png (deflated 6%)\n",
            "  adding: content/dataset_fire5_check_result/video_frame/f00038-2a9a1361-7b40-11ef-84a2-bcee7b784ecb.png (deflated 8%)\n",
            "  adding: content/dataset_fire5_check_result/video_frame/f00046-3f9da6bf-7b41-11ef-b365-bcee7b784ecb.png (deflated 3%)\n",
            "  adding: content/dataset_fire5_check_result/video_frame/f00083-422478a9-7b41-11ef-bd18-bcee7b784ecb.png (deflated 5%)\n",
            "  adding: content/dataset_fire5_check_result/video_frame/f00012-d95de3c6-7b40-11ef-b51c-bcee7b784ecb.png (deflated 7%)\n",
            "  adding: content/dataset_fire5_check_result/non-fire/ (stored 0%)\n",
            "  adding: content/dataset_fire5_check_result/non-fire/nf_01173-fcf6c5bd-7110-11ef-8698-bcee7b784ecb.png (deflated 1%)\n",
            "  adding: content/dataset_fire5_check_result/non-fire/nf_01170-fcf5b3e5-7110-11ef-81b3-bcee7b784ecb.png (deflated 1%)\n",
            "  adding: content/dataset_fire5_check_result/non-fire/nf_01171-fcf6020f-7110-11ef-817c-bcee7b784ecb.png (deflated 2%)\n",
            "  adding: content/dataset_fire5_check_result/fire/ (stored 0%)\n",
            "  adding: content/dataset_fire5_check_result/fire/f_01176-1f23ea7e-7104-11ef-8f90-bcee7b784ecb.png (deflated 4%)\n",
            "  adding: content/dataset_fire5_check_result/fire/f_01179-1f24d4d9-7104-11ef-a48f-bcee7b784ecb.png (deflated 2%)\n",
            "  adding: content/dataset_fire5_check_result/fire/f_01172-1f22d90b-7104-11ef-bb98-bcee7b784ecb.png (deflated 1%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#~ отображаю время, затраченное на выполнение всей программы\n",
        "result_time2 = time.time() - time1\n",
        "result_hour2 = int(result_time2//3600)\n",
        "result_min2 = int(result_time2//60) - result_hour2*60\n",
        "result_sec2 = int(round(result_time2%60))\n",
        "result_msec2 = round(1000*result_time2%60)\n",
        "execution_time2 = ''\n",
        "if result_hour2 > 0:\n",
        "  execution_time2 = f'Время обработки: {result_hour2} час. {result_min2} мин.'\n",
        "elif result_min2 > 0:\n",
        "  execution_time2 = f'Время обработки: {result_min2} мин. {result_sec2} сек.'\n",
        "elif result_sec2 > 0:\n",
        "  execution_time2 = f'Время обработки: {result_sec2} сек.'\n",
        "else:\n",
        "  execution_time2 = f'Время обработки: {result_msec2} мсек.'\n",
        "print(f'[INFO] {execution_time2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwrfwR8X4RiR",
        "outputId": "088f41fc-17a8-4fb6-b299-6f79080aa0d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Время обработки: 40 сек.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finish_datetime = datetime.datetime.now()\n",
        "print(f'[INFO] finish time: {finish_datetime.strftime(\"%Y.%m.%d %H:%M:%S\")}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suixt5NJ9z6u",
        "outputId": "8ebc69af-8d5b-4791-dd6c-c2cb8503eb8e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] finish time: 2024.11.08 15:30:23\n"
          ]
        }
      ]
    }
  ]
}